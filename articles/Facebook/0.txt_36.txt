UK opens probe into Facebook's psych experiment | Nation & World | The Seattle Times
LONDON --
British regulators are investigating revelations that Facebook treated hordes of its users like laboratory rats in an experiment probing into their emotions.
The Information Commissioner's Office said Wednesday that it wants to learn more about the circumstances underlying a 2-year-old study carried out by two U.S. universities and the world's largest social network.
The inquiry is being coordinated with authorities in Ireland, where Facebook has headquarters for its European operations, as well as with French regulators.
This is just the latest in a string of incidents that have raised questions about whether the privacy rights of Facebook's nearly 1.3 billion users are being trampled by the company's drive to dissect data and promote behavior that could help sell more online advertising.
In this case, Facebook allowed researchers to manipulate the content that appeared in the main section, or "news feed," of about 700,000 randomly selected users during a single week in January 2012. The data-scientists were trying to collect evidence to prove their thesis that people's moods could spread like an "emotional contagion" depending on the tenor of the content that they were reading.
The study concluded that people were more likely to post negative updates about their lives after the volume of positive information appearing in their Facebook feeds had been purposefully reduced by the researchers. The opposite reaction occurred when the number of negative posts appeared in people's news feeds.
None of the participants in the Facebook experiments were explicitly asked for their permission, though the social network's terms of use appears to allow for the company to manipulate what appears in users' news feeds however it sees fits.
Facebook's data-use policy says the Menlo Park, California, company can deploy user information for "internal operations, including troubleshooting, data analysis, testing, research and service improvement."
The reaction to the study itself provided evidence of how quickly an emotional contagion can spread online. The research was released a month ago, but it didn't provoke a backlash until the past few days after other social media sites and essays in The New York Times and The Atlantic raised red flags about the ethics of Facebook's experiment.
As it has done in several past breaches of privacy etiquette, Facebook is now trying to make amends.
Sheryl Sandberg, Facebook's chief operating officer, told television network NDTV in India that "we clearly communicated really badly about this and that we really regret." Later she added: "Facebook has apologized and certainly we never want to do anything that upsets users."
The words of contrition sounded hollow to Jeff Chester, executive director of the Center for Digital Democracy, a privacy-rights group. He points to Facebook job openings looking for researchers specializing in data mining and analysis as evidence that the company still has every intention of digging deeper into its users' psyches and preferences.
"They are engaged in secret surveillance of its users to figure out how to make more money for their advertisers," Chester said.
Whatever Facebook has been doing has been paying off for the company and its shareholders. Facebook's revenue last year rose 55 percent to $7.9 billion and its stock has nearly tripled in value during the past year.
The concern over Facebook's experiment comes amid interest in Europe about beefing up data-protection rules. The European Court of Justice last month ruled that Google must respond to users' requests seeking to remove links to personal information.
Suzy Moat, a Warwick Business School assistant professor of behavioral science, said businesses regularly do studies on how to influence behavior. She cited the example of Facebook and Amazon experimenting with showing different groups of people slightly different versions of their websites to see if one is better than another at getting customers to buy products.
"On the other hand, it's extremely understandable that many people are upset that their behavior may have been manipulated for purely scientific purposes without their consent," Moat said. "In particular, Facebook's user base is so wide that everyone wonders if they were in the experiment."
___
Liedtke reported from San Francisco. Mae Anderson in New York contributed to this report.

With apology, Facebook tries to defuse growing backlash
Facebook is trying to defuse a growing backlash over an experiment it ran on unsuspecting users in 2012.(Photo: Getty Images)
SAN FRANCISCO -- Did Facebook go too far this time?
Facebook sought to defuse a sharp backlash against the giant social network on Wednesday by publicly apologizing for running a psychology experiment on hundreds of thousands of people without their knowledge or consent.
Facebook's No. 2 executive, Chief Operating Officer Sheryl Sandberg, said the company communicated "poorly" about the experiment, which tested whether Facebook could manipulate users' emotions.
Her mea culpa came as British regulators said they had begun investigating the Facebook experiment.
Nearly a week after a report about the experiment appeared in the New Scientist magazine, the torrent of outrage shows no signs of abating. Protests have quickly spread on Facebook and social media.
"We are not experimental rats in a laboratory. What gives them the right to run experiments without our knowledge?" said Kiley Smith, a 31-year-old blogger and a daily Facebook user from Fairfax, Va. "I believe that is a personal invasion of privacy. They have definitely overstepped the bounds there."
In the week-long experiment, nearly 700,000 users were exposed either to positive or negative posts to see if the feelings would spread on the social network.
"The experiment manipulated the extent to which people were exposed to emotional expressions in their news feed," researchers wrote in their report. "These results indicate that emotions expressed by others on Facebook influence our own emotions, constituting experimental evidence for massive-scale contagion via social networks."
The research conducted with two universities was published in March.
"Given the massive scale of social networks such as Facebook, even small effects can have large aggregated consequences," the researchers concluded. "Online messages influence our experience of emotions, which may affect a variety of offline behaviours."
Facebook says it conducts this type of research to improve its service. It also says none of the information used was associated with a specific individual's Facebook account.
"This was part of ongoing research companies do to test different products, and that was what it was; it was poorly communicated," Sandberg said of the experiment, which was conducted in 2012. "And for that communication we apologize. We never meant to upset you."
But that has not mollified many users who say they were not aware that Facebook experimented on them or just how much power Facebook had to monitor and influence their behavior.
Denise Dorman, a 50-year-old writer, producer and digital content strategist from Carpentersville, Ill., says the experiment was "Orwellian."
"What's next? Will my bank lose my account balance for a day to test my reaction? Will big pharma start doling out placebos to unaware control groups for less serious maladies?" Dorman said.
Karl Volkman, chief technology officer of SRV Network in Chicago, says Facebook may not be able to shake its new public image as a digital age "Big Brother."
"If Facebook hasn't already crossed the line, they are getting very close," Volkman said.
Feeding the furor: the Facebook news feed -- and what appears in it -- was already a hotly contested subject.
People have strong feelings about the news feed. It's the main way they keep up with friends and family on Facebook.
Facebook filters the content in the news feed, and that has given rise to regular complaints that people do not see the updates they want to see.
Janet Cash, a 40-year-old middle school teacher from Davenport, Fla., says she relies on Facebook to stay in touch with far-flung family and friends and with subscribers to her newsletter. She says she has grown increasingly troubled that Facebook's computer algorithm decides what she sees in her news feed.
"I don't like Facebook manipulating my relationships," she said.
Grover Welch, a 42-year-old high school English teacher from Jonesboro, Ark., says he thinks it's more than that.
The revelation that Facebook was running tests on unsuspecting users has gotten many people to realize for the first time just how much power the giant social network has amassed, he said.
With nearly 1.3 billion users, Facebook has established itself as one of the primary means of communication and social interaction around the globe.
"People feel like they own what they put on Facebook, but they don't," Welch said. "We are investing all of our personal time into something that does not belong to us. This is the first time we have gotten a real glimpse of that."
And that -- unlike previous flaps over privacy -- has captured people's attention and shaken their faith in the service, Welch said.
"Finally people are seeing through the ruse," he said. "Facebook bills itself as being so user friendly, but they are not in it for us. This is a company, and we need to treat it like we do every other company. Everybody wants to feel like Facebook serves them, but it doesn't. Facebook serves Facebook and its investors. It has only its own self interest at heart."

