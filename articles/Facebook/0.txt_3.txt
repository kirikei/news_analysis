UK opens probe into Facebook's psych experiment | Nation & World | The Seattle Times
LONDON --
British regulators are investigating revelations that Facebook treated hordes of its users like laboratory rats in an experiment probing into their emotions.
The Information Commissioner's Office said Wednesday that it wants to learn more about the circumstances underlying a 2-year-old study carried out by two U.S. universities and the world's largest social network.
The inquiry is being coordinated with authorities in Ireland, where Facebook has headquarters for its European operations, as well as with French regulators.
This is just the latest in a string of incidents that have raised questions about whether the privacy rights of Facebook's nearly 1.3 billion users are being trampled by the company's drive to dissect data and promote behavior that could help sell more online advertising.
In this case, Facebook allowed researchers to manipulate the content that appeared in the main section, or "news feed," of about 700,000 randomly selected users during a single week in January 2012. The data-scientists were trying to collect evidence to prove their thesis that people's moods could spread like an "emotional contagion" depending on the tenor of the content that they were reading.
The study concluded that people were more likely to post negative updates about their lives after the volume of positive information appearing in their Facebook feeds had been purposefully reduced by the researchers. The opposite reaction occurred when the number of negative posts appeared in people's news feeds.
None of the participants in the Facebook experiments were explicitly asked for their permission, though the social network's terms of use appears to allow for the company to manipulate what appears in users' news feeds however it sees fits.
Facebook's data-use policy says the Menlo Park, California, company can deploy user information for "internal operations, including troubleshooting, data analysis, testing, research and service improvement."
The reaction to the study itself provided evidence of how quickly an emotional contagion can spread online. The research was released a month ago, but it didn't provoke a backlash until the past few days after other social media sites and essays in The New York Times and The Atlantic raised red flags about the ethics of Facebook's experiment.
As it has done in several past breaches of privacy etiquette, Facebook is now trying to make amends.
Sheryl Sandberg, Facebook's chief operating officer, told television network NDTV in India that "we clearly communicated really badly about this and that we really regret." Later she added: "Facebook has apologized and certainly we never want to do anything that upsets users."
The words of contrition sounded hollow to Jeff Chester, executive director of the Center for Digital Democracy, a privacy-rights group. He points to Facebook job openings looking for researchers specializing in data mining and analysis as evidence that the company still has every intention of digging deeper into its users' psyches and preferences.
"They are engaged in secret surveillance of its users to figure out how to make more money for their advertisers," Chester said.
Whatever Facebook has been doing has been paying off for the company and its shareholders. Facebook's revenue last year rose 55 percent to $7.9 billion and its stock has nearly tripled in value during the past year.
The concern over Facebook's experiment comes amid interest in Europe about beefing up data-protection rules. The European Court of Justice last month ruled that Google must respond to users' requests seeking to remove links to personal information.
Suzy Moat, a Warwick Business School assistant professor of behavioral science, said businesses regularly do studies on how to influence behavior. She cited the example of Facebook and Amazon experimenting with showing different groups of people slightly different versions of their websites to see if one is better than another at getting customers to buy products.
"On the other hand, it's extremely understandable that many people are upset that their behavior may have been manipulated for purely scientific purposes without their consent," Moat said. "In particular, Facebook's user base is so wide that everyone wonders if they were in the experiment."
___
Liedtke reported from San Francisco. Mae Anderson in New York contributed to this report.

Facebook 'conducted widespread experiments' on user data to 'alter people's behaviour' - Telegraph
In one experiment described by the newspaper, thousands of users received a message that they were being locked out of the social network because Facebook believed they were robots or using fake names. The message was actually a test designed to help improve Facebook's antifraud measures.
Mr Ledvina described discussions within the team about conducting other tests without informing users. "I'm sure some people got very angry somewhere," he said. "Internally, you get a little desensitised to it."
Facebook's data science team has reportedly run hundreds of tests and studies without the knowledge or explicit content of participants since its creation in 2007, relying on the broad terms of service agreement in which state that user data can be used for research.
The controversy about the human emotions experiment took Facebook by surprise after its organisers published the details in an academic study.
The company said that it has now implemented stricter controls on the activities of its data science team, including reviews by a 50-person panel of unnamed experts in data security and privacy. "We are taking a very hard look at this process to make more improvements," a spokesman said.
Sheryl Sandberg, Facebook's chief operating officer, this week apologised that the study was "poorly communicated", but not for the research itself.
Although all major internet players such as Google, Yahoo and Twitter study users habits and data, there are particular concerns about Facebook's activities as its contributors post such personal information about their lives, beliefs and emotions.
The latest revelations have fuelled criticisms that the company's regular changes to users' news feeds - its key structure - are at best shameless and at worst sinister attempts to mould and shape how people act online.
The company has recruited psychologists, behavioural experts and social scientists from the academic world and its internet rivals to bolster its data science and research operations.
Adam Kramer, the lead author of the emotions study, took to Facebook itself with a posting this week to address concerns about the work.
"In hindsight, the research benefits of the paper may not have justified all of this anxiety," he wrote. "The experiment in question was run in early 2012, and we have come a long way since then. Those [new] review practices will also incorporate what we've learned from the reaction to this paper."
But in an earlier interview on the company's website, Mr Kramer, who holds a doctorate in social psychology, explained the allure of conducting research at Facebook. It was "the largest field study in the history of the world", he said. "I just message someone on the right team and my research has an impact within weeks, if not days."
Cameron Marlow, the head of the data science operations, was similarly enthusiastic in an interview with the Technology Review website. "For the first time, we have a microscope that not only lets us examine social behaviour at a very fine level that we've never been able to see before but allows us to run experiments that millions of users are exposed to," he said.
"This is the first time the world has seen this scale and quality of data about human communication."
Even before the controversy about the human emotions study, Technology Review reported that one of Mr Marlow's researchers had developed a way to calculate a country's "gross national happiness" from the Facebook activity of its citizens, by logging the occurrence of words and phrases that signal positive or negative moods.
