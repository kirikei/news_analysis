UK opens probe into Facebook's psych experiment | Nation & World | The Seattle Times
LONDON --
British regulators are investigating revelations that Facebook treated hordes of its users like laboratory rats in an experiment probing into their emotions.
The Information Commissioner's Office said Wednesday that it wants to learn more about the circumstances underlying a 2-year-old study carried out by two U.S. universities and the world's largest social network.
The inquiry is being coordinated with authorities in Ireland, where Facebook has headquarters for its European operations, as well as with French regulators.
This is just the latest in a string of incidents that have raised questions about whether the privacy rights of Facebook's nearly 1.3 billion users are being trampled by the company's drive to dissect data and promote behavior that could help sell more online advertising.
In this case, Facebook allowed researchers to manipulate the content that appeared in the main section, or "news feed," of about 700,000 randomly selected users during a single week in January 2012. The data-scientists were trying to collect evidence to prove their thesis that people's moods could spread like an "emotional contagion" depending on the tenor of the content that they were reading.
The study concluded that people were more likely to post negative updates about their lives after the volume of positive information appearing in their Facebook feeds had been purposefully reduced by the researchers. The opposite reaction occurred when the number of negative posts appeared in people's news feeds.
None of the participants in the Facebook experiments were explicitly asked for their permission, though the social network's terms of use appears to allow for the company to manipulate what appears in users' news feeds however it sees fits.
Facebook's data-use policy says the Menlo Park, California, company can deploy user information for "internal operations, including troubleshooting, data analysis, testing, research and service improvement."
The reaction to the study itself provided evidence of how quickly an emotional contagion can spread online. The research was released a month ago, but it didn't provoke a backlash until the past few days after other social media sites and essays in The New York Times and The Atlantic raised red flags about the ethics of Facebook's experiment.
As it has done in several past breaches of privacy etiquette, Facebook is now trying to make amends.
Sheryl Sandberg, Facebook's chief operating officer, told television network NDTV in India that "we clearly communicated really badly about this and that we really regret." Later she added: "Facebook has apologized and certainly we never want to do anything that upsets users."
The words of contrition sounded hollow to Jeff Chester, executive director of the Center for Digital Democracy, a privacy-rights group. He points to Facebook job openings looking for researchers specializing in data mining and analysis as evidence that the company still has every intention of digging deeper into its users' psyches and preferences.
"They are engaged in secret surveillance of its users to figure out how to make more money for their advertisers," Chester said.
Whatever Facebook has been doing has been paying off for the company and its shareholders. Facebook's revenue last year rose 55 percent to $7.9 billion and its stock has nearly tripled in value during the past year.
The concern over Facebook's experiment comes amid interest in Europe about beefing up data-protection rules. The European Court of Justice last month ruled that Google must respond to users' requests seeking to remove links to personal information.
Suzy Moat, a Warwick Business School assistant professor of behavioral science, said businesses regularly do studies on how to influence behavior. She cited the example of Facebook and Amazon experimenting with showing different groups of people slightly different versions of their websites to see if one is better than another at getting customers to buy products.
"On the other hand, it's extremely understandable that many people are upset that their behavior may have been manipulated for purely scientific purposes without their consent," Moat said. "In particular, Facebook's user base is so wide that everyone wonders if they were in the experiment."
___
Liedtke reported from San Francisco. Mae Anderson in New York contributed to this report.

Facebook's study got it wrong: seeing our 'friends' happy can make us sad | Jess Zimmerman | Comment is free | theguardian.com
It's cute that Facebook was apparently trying to make me sad by suppressing my friends' good-news updates so that I feel surrounded by anxiety and illness, in order to measure the effects of "contagion" on users' emotional states. Well, "cute" in the manner of a creepy social experiment on uninformed participants, so maybe not really the standard usage of "cute". Remember Dexter's Laboratory, the cartoon where the little kid was always plotting world-destroying antics but was also two feet tall and six years old? Cute like that.
Anyway, the point is: bless their invasive little hearts, but this was doomed from the start. People don't get sad because their Facebook friends are sad. We get sad because our Facebook "friends" are happy.
This is not me being cynical - of course I'm capable of empathy for the people I care about, and vice versa. No, this is a matter of Facebook not understanding its own product. For the average Facebook user, only a fraction of our "friends" are actually people we love - people whose setbacks strike us near to the heart, people whose triumphs uplift us along with them. The rest are former co-workers, friends of friends from that party that one time, people who were jerks to us in high school but not big enough jerks to reject their friend requests, and exes. Screw those guys.
I realize that scientific progress sometimes means performing rigorous research on questions that seem self-evident. (I also realize that this research is supposed to be done on people who know they're participating in a research investigation; never mind that right now.) But you don't need a study, informed or not, to tell you that the connection between our emotions and those of people around us are a lot more complicated than "sad=sad". All you need to do is look at a happy Facebook pic from your ex's wedding.
The study in question, published in the Proceedings of the National Academy of Science, reports that, for a week in January 2012, some Facebook users saw an altered timeline wherein posts with either "negative" or "positive" words got suppressed. A lot of the hand-wringing horror over this unauthorized experiment stems from the reality that users who were exposed to more negative content responded by making more negative posts, which implies that they were more sad. In other words, they were materially harmed by their experience as social-science abductees.
But the study doesn't seem to control for the possibility that people simply match their tone and word choice to that of their peers, to avoid being the tall poppy. In the end, it's not clear that Facebook found out anything about emotional contagion. It sounds more like semantic contagion to me.
If Facebook really wanted to make people experience unhappiness, suppressing "positive words" isn't going to do the trick. Emotions are way more complicated than the mere words we use, and it's not always posts with negative words that make us sad.
For its next mad-scientist foray into emotional manipulation, Facebook and Co should instead try building a news feed where users see only the following:
Notifications of career success from an acquaintance who is in the same field as you, but younger
Mushy "Happy anniversary, baby!" notes from your ex's new significant other
Cute snapshots of your friends' young child who they say is doing so well since they opted not to get him vaccinated
Triumphant posts of celebration from people who root for a different team/candidate than you
Memes involving a photo of a beach or flower overlaid with encouraging platitudes with at least two obvious typos
Off-the-chart FitBit stats
Profile pictures making it clear that the mean, gorgeous queen bee from high school is still - against any reasonable expectation of biology or justice - extremely gorgeous
Birth announcements from dear friends who gave their offspring really stupid names
I doubt there would be a "negative word" among them, but I guarantee you the emotional contagion would be off the charts.
