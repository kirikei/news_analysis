UK opens probe into Facebook's psych experiment | Nation & World | The Seattle Times
LONDON --
British regulators are investigating revelations that Facebook treated hordes of its users like laboratory rats in an experiment probing into their emotions.
The Information Commissioner's Office said Wednesday that it wants to learn more about the circumstances underlying a 2-year-old study carried out by two U.S. universities and the world's largest social network.
The inquiry is being coordinated with authorities in Ireland, where Facebook has headquarters for its European operations, as well as with French regulators.
This is just the latest in a string of incidents that have raised questions about whether the privacy rights of Facebook's nearly 1.3 billion users are being trampled by the company's drive to dissect data and promote behavior that could help sell more online advertising.
In this case, Facebook allowed researchers to manipulate the content that appeared in the main section, or "news feed," of about 700,000 randomly selected users during a single week in January 2012. The data-scientists were trying to collect evidence to prove their thesis that people's moods could spread like an "emotional contagion" depending on the tenor of the content that they were reading.
The study concluded that people were more likely to post negative updates about their lives after the volume of positive information appearing in their Facebook feeds had been purposefully reduced by the researchers. The opposite reaction occurred when the number of negative posts appeared in people's news feeds.
None of the participants in the Facebook experiments were explicitly asked for their permission, though the social network's terms of use appears to allow for the company to manipulate what appears in users' news feeds however it sees fits.
Facebook's data-use policy says the Menlo Park, California, company can deploy user information for "internal operations, including troubleshooting, data analysis, testing, research and service improvement."
The reaction to the study itself provided evidence of how quickly an emotional contagion can spread online. The research was released a month ago, but it didn't provoke a backlash until the past few days after other social media sites and essays in The New York Times and The Atlantic raised red flags about the ethics of Facebook's experiment.
As it has done in several past breaches of privacy etiquette, Facebook is now trying to make amends.
Sheryl Sandberg, Facebook's chief operating officer, told television network NDTV in India that "we clearly communicated really badly about this and that we really regret." Later she added: "Facebook has apologized and certainly we never want to do anything that upsets users."
The words of contrition sounded hollow to Jeff Chester, executive director of the Center for Digital Democracy, a privacy-rights group. He points to Facebook job openings looking for researchers specializing in data mining and analysis as evidence that the company still has every intention of digging deeper into its users' psyches and preferences.
"They are engaged in secret surveillance of its users to figure out how to make more money for their advertisers," Chester said.
Whatever Facebook has been doing has been paying off for the company and its shareholders. Facebook's revenue last year rose 55 percent to $7.9 billion and its stock has nearly tripled in value during the past year.
The concern over Facebook's experiment comes amid interest in Europe about beefing up data-protection rules. The European Court of Justice last month ruled that Google must respond to users' requests seeking to remove links to personal information.
Suzy Moat, a Warwick Business School assistant professor of behavioral science, said businesses regularly do studies on how to influence behavior. She cited the example of Facebook and Amazon experimenting with showing different groups of people slightly different versions of their websites to see if one is better than another at getting customers to buy products.
"On the other hand, it's extremely understandable that many people are upset that their behavior may have been manipulated for purely scientific purposes without their consent," Moat said. "In particular, Facebook's user base is so wide that everyone wonders if they were in the experiment."
___
Liedtke reported from San Francisco. Mae Anderson in New York contributed to this report.

Facebook could face an investigation by the US Federate Trade Commission (FTC) over its use of user data in the controversial "emotion contagion" experiment.
The US privacy pressure group the Electronic Privacy Information Centre (Epic) has filed a complaint with FTC demanding that the watchdog investigate Facebook's actions.
"The company purposefully messed with people's minds," states Epic in the complaint. "Facebook conducted the psychological experiment with researchers at Cornell University and the University of California, San Francisco, who failed to follow standard ethical protocols for human subject research."
The study conducted over one week in 2012 and published in the Proceedings of National Academy of Sciences, hid "a small percentage" of emotional words from peoples' news feeds, without their knowledge, to test what effect that had on the statuses or "likes" that they then posted or reacted to.
'Unfair and deceptive' acts and practices
"Facebook's conduct is both a deceptive trade practice under Section 5 of the FTC Act and a violation of the Commission's 2012 Consent Order," the complaint continues.
The FTC Act prohibits "unfair and deceptive" acts and practices, which Epic alleges Facebook's actions within the Cornell study countermand.
Facebook is also currently under a 20 year consent decree from the FTC that requires Facebook to protect user privacy, first imposed in July 2012, after an FTC investigation found the social network to be in volition of the FTC Act in the US.
The settlement caused Facebook to increase its privacy and security of information measures, as well as preventing the social network from misrepresenting the extent to which user data is held as private.
"Facebook's failure to adequately disclose that it shared consumer data with third-party researchers constitutes a deceptive act or practice in violation of Section 5(a) of the FTC Act," states the Epic complaint. "Facebook has violated Count I of its 2012 Consent Order with the FTC and is subject to FTC enforcement in Federal district court."
Epic demands that Facebook makes public the NewsFeed algorithm
As well as demanding that the FTC conducts an investigation into the study and sharing of data without explicit user consent with third-party researchers at Cornell University, Epic demands that Facebook makes public the proprietary algorithm that produces the NewsFeed.
The FTC last investigated Facebook after the company made changes to the way information privacy was handled making some previously private information - such as friends lists - public without warning or approval in advance.
The company settled with the FTC in November 2011 over the what the regulator described as Facebook "deceiving consumers by telling them they could keep their information on Facebook private, and then repeatedly allowing it to be shared and made public."
The settlement included a clause that forces Facebook to obtain consent for making any changes to privacy settings, something Epic alleges was not the case for the nearly 700,000 users unwittingly involved in the "emotion contagion" study.
Epic was part of the original complaint group in 2009 and 2010 that induced the investigation by the FTC.
Facebook declined to comment.
* Facebook denies military ties for its emotion contagion research
